{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                                     name  gradient   parameters                shape         mu      sigma\n",
      "    0                      model.0.conv.weight     False          432        [16, 3, 3, 3]   -0.00279      0.152 torch.float32\n",
      "    1                        model.0.bn.weight     False           16                 [16]       2.97       1.86 torch.float32\n",
      "    2                          model.0.bn.bias     False           16                 [16]      0.249       4.17 torch.float32\n",
      "    3                      model.1.conv.weight     False         4608       [32, 16, 3, 3]   -0.00012      0.063 torch.float32\n",
      "    4                        model.1.bn.weight     False           32                 [32]       5.02       1.12 torch.float32\n",
      "    5                          model.1.bn.bias     False           32                 [32]      0.942        1.5 torch.float32\n",
      "    6                  model.2.cv1.conv.weight     False         1024       [32, 32, 1, 1]     -0.011     0.0906 torch.float32\n",
      "    7                    model.2.cv1.bn.weight     False           32                 [32]       2.22       1.39 torch.float32\n",
      "    8                      model.2.cv1.bn.bias     False           32                 [32]      0.802       1.38 torch.float32\n",
      "    9                  model.2.cv2.conv.weight     False         1536       [32, 48, 1, 1]    -0.0045      0.082 torch.float32\n",
      "   10                    model.2.cv2.bn.weight     False           32                 [32]       1.21      0.581 torch.float32\n",
      "   11                      model.2.cv2.bn.bias     False           32                 [32]      0.544       1.12 torch.float32\n",
      "   12              model.2.m.0.cv1.conv.weight     False         2304       [16, 16, 3, 3]   -0.00119     0.0558 torch.float32\n",
      "   13                model.2.m.0.cv1.bn.weight     False           16                 [16]       2.36      0.719 torch.float32\n",
      "   14                  model.2.m.0.cv1.bn.bias     False           16                 [16]       1.03        1.7 torch.float32\n",
      "   15              model.2.m.0.cv2.conv.weight     False         2304       [16, 16, 3, 3]  -0.000189     0.0477 torch.float32\n",
      "   16                model.2.m.0.cv2.bn.weight     False           16                 [16]       2.11      0.513 torch.float32\n",
      "   17                  model.2.m.0.cv2.bn.bias     False           16                 [16]      0.919       1.89 torch.float32\n",
      "   18                      model.3.conv.weight     False        18432       [64, 32, 3, 3]   -0.00152     0.0317 torch.float32\n",
      "   19                        model.3.bn.weight     False           64                 [64]      0.817      0.207 torch.float32\n",
      "   20                          model.3.bn.bias     False           64                 [64]      0.253       0.93 torch.float32\n",
      "   21                  model.4.cv1.conv.weight     False         4096       [64, 64, 1, 1]   -0.00269     0.0534 torch.float32\n",
      "   22                    model.4.cv1.bn.weight     False           64                 [64]      0.819      0.361 torch.float32\n",
      "   23                      model.4.cv1.bn.bias     False           64                 [64]      0.261       0.78 torch.float32\n",
      "   24                  model.4.cv2.conv.weight     False         8192      [64, 128, 1, 1]   -0.00208     0.0456 torch.float32\n",
      "   25                    model.4.cv2.bn.weight     False           64                 [64]      0.712       0.21 torch.float32\n",
      "   26                      model.4.cv2.bn.bias     False           64                 [64]    -0.0523      0.753 torch.float32\n",
      "   27              model.4.m.0.cv1.conv.weight     False         9216       [32, 32, 3, 3]   -0.00148     0.0341 torch.float32\n",
      "   28                model.4.m.0.cv1.bn.weight     False           32                 [32]      0.748      0.155 torch.float32\n",
      "   29                  model.4.m.0.cv1.bn.bias     False           32                 [32]     -0.257      0.629 torch.float32\n",
      "   30              model.4.m.0.cv2.conv.weight     False         9216       [32, 32, 3, 3]   -0.00153     0.0316 torch.float32\n",
      "   31                model.4.m.0.cv2.bn.weight     False           32                 [32]      0.775        0.2 torch.float32\n",
      "   32                  model.4.m.0.cv2.bn.bias     False           32                 [32]      0.195      0.696 torch.float32\n",
      "   33              model.4.m.1.cv1.conv.weight     False         9216       [32, 32, 3, 3]   -0.00224      0.031 torch.float32\n",
      "   34                model.4.m.1.cv1.bn.weight     False           32                 [32]      0.682      0.106 torch.float32\n",
      "   35                  model.4.m.1.cv1.bn.bias     False           32                 [32]     -0.816      0.473 torch.float32\n",
      "   36              model.4.m.1.cv2.conv.weight     False         9216       [32, 32, 3, 3]   -0.00179     0.0276 torch.float32\n",
      "   37                model.4.m.1.cv2.bn.weight     False           32                 [32]       1.05      0.241 torch.float32\n",
      "   38                  model.4.m.1.cv2.bn.bias     False           32                 [32]      0.527      0.863 torch.float32\n",
      "   39                      model.5.conv.weight     False        73728      [128, 64, 3, 3]  -0.000401     0.0189 torch.float32\n",
      "   40                        model.5.bn.weight     False          128                [128]      0.822      0.231 torch.float32\n",
      "   41                          model.5.bn.bias     False          128                [128]     -0.233      0.677 torch.float32\n",
      "   42                  model.6.cv1.conv.weight     False        16384     [128, 128, 1, 1]   -0.00239     0.0326 torch.float32\n",
      "   43                    model.6.cv1.bn.weight     False          128                [128]      0.895        0.4 torch.float32\n",
      "   44                      model.6.cv1.bn.bias     False          128                [128]     -0.135      0.745 torch.float32\n",
      "   45                  model.6.cv2.conv.weight     False        32768     [128, 256, 1, 1]   -0.00184     0.0283 torch.float32\n",
      "   46                    model.6.cv2.bn.weight     False          128                [128]      0.769      0.206 torch.float32\n",
      "   47                      model.6.cv2.bn.bias     False          128                [128]     -0.588      0.754 torch.float32\n",
      "   48              model.6.m.0.cv1.conv.weight     False        36864       [64, 64, 3, 3]    -0.0015     0.0203 torch.float32\n",
      "   49                model.6.m.0.cv1.bn.weight     False           64                 [64]       1.06      0.177 torch.float32\n",
      "   50                  model.6.m.0.cv1.bn.bias     False           64                 [64]     -0.912        0.6 torch.float32\n",
      "   51              model.6.m.0.cv2.conv.weight     False        36864       [64, 64, 3, 3]   -0.00149     0.0188 torch.float32\n",
      "   52                model.6.m.0.cv2.bn.weight     False           64                 [64]      0.835      0.248 torch.float32\n",
      "   53                  model.6.m.0.cv2.bn.bias     False           64                 [64]    -0.0764      0.526 torch.float32\n",
      "   54              model.6.m.1.cv1.conv.weight     False        36864       [64, 64, 3, 3]   -0.00166     0.0192 torch.float32\n",
      "   55                model.6.m.1.cv1.bn.weight     False           64                 [64]      0.918      0.175 torch.float32\n",
      "   56                  model.6.m.1.cv1.bn.bias     False           64                 [64]      -1.13      0.734 torch.float32\n",
      "   57              model.6.m.1.cv2.conv.weight     False        36864       [64, 64, 3, 3]  -0.000996      0.018 torch.float32\n",
      "   58                model.6.m.1.cv2.bn.weight     False           64                 [64]       1.18      0.277 torch.float32\n",
      "   59                  model.6.m.1.cv2.bn.bias     False           64                 [64]      0.208      0.765 torch.float32\n",
      "   60                      model.7.conv.weight     False       294912     [256, 128, 3, 3]  -0.000505     0.0115 torch.float32\n",
      "   61                        model.7.bn.weight     False          256                [256]      0.961      0.196 torch.float32\n",
      "   62                          model.7.bn.bias     False          256                [256]     -0.718       0.45 torch.float32\n",
      "   63                  model.8.cv1.conv.weight     False        65536     [256, 256, 1, 1]   -0.00268     0.0204 torch.float32\n",
      "   64                    model.8.cv1.bn.weight     False          256                [256]       1.14       0.33 torch.float32\n",
      "   65                      model.8.cv1.bn.bias     False          256                [256]     -0.736      0.573 torch.float32\n",
      "   66                  model.8.cv2.conv.weight     False        98304     [256, 384, 1, 1]   -0.00162     0.0174 torch.float32\n",
      "   67                    model.8.cv2.bn.weight     False          256                [256]       1.19      0.223 torch.float32\n",
      "   68                      model.8.cv2.bn.bias     False          256                [256]     -0.689      0.484 torch.float32\n",
      "   69              model.8.m.0.cv1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000843     0.0128 torch.float32\n",
      "   70                model.8.m.0.cv1.bn.weight     False          128                [128]       1.14      0.205 torch.float32\n",
      "   71                  model.8.m.0.cv1.bn.bias     False          128                [128]     -0.822      0.719 torch.float32\n",
      "   72              model.8.m.0.cv2.conv.weight     False       147456     [128, 128, 3, 3]   -0.00101     0.0124 torch.float32\n",
      "   73                model.8.m.0.cv2.bn.weight     False          128                [128]       1.65      0.368 torch.float32\n",
      "   74                  model.8.m.0.cv2.bn.bias     False          128                [128]     -0.199      0.607 torch.float32\n",
      "   75                  model.9.cv1.conv.weight     False        32768     [128, 256, 1, 1]   -0.00378     0.0238 torch.float32\n",
      "   76                    model.9.cv1.bn.weight     False          128                [128]      0.926      0.248 torch.float32\n",
      "   77                      model.9.cv1.bn.bias     False          128                [128]       1.43      0.657 torch.float32\n",
      "   78                  model.9.cv2.conv.weight     False       131072     [256, 512, 1, 1]    6.2e-05      0.015 torch.float32\n",
      "   79                    model.9.cv2.bn.weight     False          256                [256]      0.942      0.255 torch.float32\n",
      "   80                      model.9.cv2.bn.bias     False          256                [256]      -1.26       0.83 torch.float32\n",
      "   81                 model.12.cv1.conv.weight     False        49152     [128, 384, 1, 1]   -0.00209      0.023 torch.float32\n",
      "   82                   model.12.cv1.bn.weight     False          128                [128]      0.873      0.222 torch.float32\n",
      "   83                     model.12.cv1.bn.bias     False          128                [128]     -0.371      0.819 torch.float32\n",
      "   84                 model.12.cv2.conv.weight     False        24576     [128, 192, 1, 1]   -0.00362     0.0259 torch.float32\n",
      "   85                   model.12.cv2.bn.weight     False          128                [128]      0.739      0.198 torch.float32\n",
      "   86                     model.12.cv2.bn.bias     False          128                [128]     -0.271      0.661 torch.float32\n",
      "   87             model.12.m.0.cv1.conv.weight     False        36864       [64, 64, 3, 3]   -0.00153     0.0193 torch.float32\n",
      "   88               model.12.m.0.cv1.bn.weight     False           64                 [64]      0.833      0.138 torch.float32\n",
      "   89                 model.12.m.0.cv1.bn.bias     False           64                 [64]     -0.837       0.61 torch.float32\n",
      "   90             model.12.m.0.cv2.conv.weight     False        36864       [64, 64, 3, 3]  -0.000776     0.0179 torch.float32\n",
      "   91               model.12.m.0.cv2.bn.weight     False           64                 [64]      0.822      0.181 torch.float32\n",
      "   92                 model.12.m.0.cv2.bn.bias     False           64                 [64]     -0.106      0.635 torch.float32\n",
      "   93                 model.15.cv1.conv.weight     False        12288      [64, 192, 1, 1]   -0.00152     0.0297 torch.float32\n",
      "   94                   model.15.cv1.bn.weight     False           64                 [64]      0.541      0.214 torch.float32\n",
      "   95                     model.15.cv1.bn.bias     False           64                 [64]      0.166      0.965 torch.float32\n",
      "   96                 model.15.cv2.conv.weight     False         6144       [64, 96, 1, 1]  -0.000505     0.0346 torch.float32\n",
      "   97                   model.15.cv2.bn.weight     False           64                 [64]      0.567      0.264 torch.float32\n",
      "   98                     model.15.cv2.bn.bias     False           64                 [64]      0.134      0.946 torch.float32\n",
      "   99             model.15.m.0.cv1.conv.weight     False         9216       [32, 32, 3, 3]   -0.00172     0.0279 torch.float32\n",
      "  100               model.15.m.0.cv1.bn.weight     False           32                 [32]      0.663       0.14 torch.float32\n",
      "  101                 model.15.m.0.cv1.bn.bias     False           32                 [32]     -0.564      0.582 torch.float32\n",
      "  102             model.15.m.0.cv2.conv.weight     False         9216       [32, 32, 3, 3]  -0.000878     0.0261 torch.float32\n",
      "  103               model.15.m.0.cv2.bn.weight     False           32                 [32]      0.734      0.162 torch.float32\n",
      "  104                 model.15.m.0.cv2.bn.bias     False           32                 [32]      0.207      0.785 torch.float32\n",
      "  105                     model.16.conv.weight     False        36864       [64, 64, 3, 3]  -0.000385     0.0134 torch.float32\n",
      "  106                       model.16.bn.weight     False           64                 [64]      0.842      0.213 torch.float32\n",
      "  107                         model.16.bn.bias     False           64                 [64]     -0.388       0.59 torch.float32\n",
      "  108                 model.18.cv1.conv.weight     False        24576     [128, 192, 1, 1]   -0.00125     0.0212 torch.float32\n",
      "  109                   model.18.cv1.bn.weight     False          128                [128]      0.885      0.205 torch.float32\n",
      "  110                     model.18.cv1.bn.bias     False          128                [128]     -0.298      0.609 torch.float32\n",
      "  111                 model.18.cv2.conv.weight     False        24576     [128, 192, 1, 1]  -0.000884     0.0206 torch.float32\n",
      "  112                   model.18.cv2.bn.weight     False          128                [128]      0.734      0.292 torch.float32\n",
      "  113                     model.18.cv2.bn.bias     False          128                [128]     -0.427      0.761 torch.float32\n",
      "  114             model.18.m.0.cv1.conv.weight     False        36864       [64, 64, 3, 3]    -0.0014     0.0165 torch.float32\n",
      "  115               model.18.m.0.cv1.bn.weight     False           64                 [64]        0.8      0.177 torch.float32\n",
      "  116                 model.18.m.0.cv1.bn.bias     False           64                 [64]     -0.772       0.49 torch.float32\n",
      "  117             model.18.m.0.cv2.conv.weight     False        36864       [64, 64, 3, 3]  -0.000584     0.0152 torch.float32\n",
      "  118               model.18.m.0.cv2.bn.weight     False           64                 [64]       1.19      0.286 torch.float32\n",
      "  119                 model.18.m.0.cv2.bn.bias     False           64                 [64]    -0.0701      0.665 torch.float32\n",
      "  120                     model.19.conv.weight     False       147456     [128, 128, 3, 3]  -0.000376    0.00768 torch.float32\n",
      "  121                       model.19.bn.weight     False          128                [128]      0.877       0.21 torch.float32\n",
      "  122                         model.19.bn.bias     False          128                [128]     -0.507      0.364 torch.float32\n",
      "  123                 model.21.cv1.conv.weight     False        98304     [256, 384, 1, 1]   -0.00112     0.0124 torch.float32\n",
      "  124                   model.21.cv1.bn.weight     False          256                [256]       1.06      0.228 torch.float32\n",
      "  125                     model.21.cv1.bn.bias     False          256                [256]      -0.59      0.577 torch.float32\n",
      "  126                 model.21.cv2.conv.weight     False        98304     [256, 384, 1, 1]   -0.00096     0.0109 torch.float32\n",
      "  127                   model.21.cv2.bn.weight     False          256                [256]       1.04      0.317 torch.float32\n",
      "  128                     model.21.cv2.bn.bias     False          256                [256]      -0.89      0.489 torch.float32\n",
      "  129             model.21.m.0.cv1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000713    0.00903 torch.float32\n",
      "  130               model.21.m.0.cv1.bn.weight     False          128                [128]       1.03      0.223 torch.float32\n",
      "  131                 model.21.m.0.cv1.bn.bias     False          128                [128]      -0.96      0.617 torch.float32\n",
      "  132             model.21.m.0.cv2.conv.weight     False       147456     [128, 128, 3, 3]   -0.00042     0.0083 torch.float32\n",
      "  133               model.21.m.0.cv2.bn.weight     False          128                [128]       1.36      0.252 torch.float32\n",
      "  134                 model.21.m.0.cv2.bn.bias     False          128                [128]      -0.55      0.517 torch.float32\n",
      "  135             model.22.cv2.0.0.conv.weight     False        36864       [64, 64, 3, 3]  -0.000871     0.0138 torch.float32\n",
      "  136               model.22.cv2.0.0.bn.weight     False           64                 [64]      0.882      0.357 torch.float32\n",
      "  137                 model.22.cv2.0.0.bn.bias     False           64                 [64]     -0.501      0.702 torch.float32\n",
      "  138             model.22.cv2.0.1.conv.weight     False        36864       [64, 64, 3, 3]  -0.000302     0.0121 torch.float32\n",
      "  139               model.22.cv2.0.1.bn.weight     False           64                 [64]       2.41       1.04 torch.float32\n",
      "  140                 model.22.cv2.0.1.bn.bias     False           64                 [64]      0.923      0.752 torch.float32\n",
      "  141                  model.22.cv2.0.2.weight     False         4096       [64, 64, 1, 1]   5.55e-07     0.0503 torch.float32\n",
      "  142                    model.22.cv2.0.2.bias     False           64                 [64]          1       1.39 torch.float32\n",
      "  143             model.22.cv2.1.0.conv.weight     False        73728      [64, 128, 3, 3]  -0.000461    0.00909 torch.float32\n",
      "  144               model.22.cv2.1.0.bn.weight     False           64                 [64]       1.29      0.492 torch.float32\n",
      "  145                 model.22.cv2.1.0.bn.bias     False           64                 [64]     -0.394      0.673 torch.float32\n",
      "  146             model.22.cv2.1.1.conv.weight     False        36864       [64, 64, 3, 3]  -0.000135     0.0113 torch.float32\n",
      "  147               model.22.cv2.1.1.bn.weight     False           64                 [64]       2.56          1 torch.float32\n",
      "  148                 model.22.cv2.1.1.bn.bias     False           64                 [64]      0.856      0.562 torch.float32\n",
      "  149                  model.22.cv2.1.2.weight     False         4096       [64, 64, 1, 1]  -4.08e-07     0.0548 torch.float32\n",
      "  150                    model.22.cv2.1.2.bias     False           64                 [64]      0.999       1.31 torch.float32\n",
      "  151             model.22.cv2.2.0.conv.weight     False       147456      [64, 256, 3, 3]  -0.000226    0.00654 torch.float32\n",
      "  152               model.22.cv2.2.0.bn.weight     False           64                 [64]       1.55      0.415 torch.float32\n",
      "  153                 model.22.cv2.2.0.bn.bias     False           64                 [64]     -0.257      0.617 torch.float32\n",
      "  154             model.22.cv2.2.1.conv.weight     False        36864       [64, 64, 3, 3]  -0.000172     0.0105 torch.float32\n",
      "  155               model.22.cv2.2.1.bn.weight     False           64                 [64]       2.95      0.853 torch.float32\n",
      "  156                 model.22.cv2.2.1.bn.bias     False           64                 [64]      0.826      0.555 torch.float32\n",
      "  157                  model.22.cv2.2.2.weight     False         4096       [64, 64, 1, 1]   5.78e-06     0.0593 torch.float32\n",
      "  158                    model.22.cv2.2.2.bias     False           64                 [64]          1       1.32 torch.float32\n",
      "  159             model.22.cv3.0.0.conv.weight     False        46080       [80, 64, 3, 3]  -0.000739     0.0119 torch.float32\n",
      "  160               model.22.cv3.0.0.bn.weight     False           80                 [80]      0.697      0.247 torch.float32\n",
      "  161                 model.22.cv3.0.0.bn.bias     False           80                 [80]      -0.58      0.767 torch.float32\n",
      "  162             model.22.cv3.0.1.conv.weight     False        57600       [80, 80, 3, 3]  -0.000899       0.01 torch.float32\n",
      "  163               model.22.cv3.0.1.bn.weight     False           80                 [80]       2.75      0.655 torch.float32\n",
      "  164                 model.22.cv3.0.1.bn.bias     False           80                 [80]       1.34       1.83 torch.float32\n",
      "  165                  model.22.cv3.0.2.weight     False         6400       [80, 80, 1, 1]    -0.0123     0.0532 torch.float32\n",
      "  166                    model.22.cv3.0.2.bias     False           80                 [80]      -11.4       1.11 torch.float32\n",
      "  167             model.22.cv3.1.0.conv.weight     False        92160      [80, 128, 3, 3]  -0.000437    0.00858 torch.float32\n",
      "  168               model.22.cv3.1.0.bn.weight     False           80                 [80]      0.872       0.28 torch.float32\n",
      "  169                 model.22.cv3.1.0.bn.bias     False           80                 [80]     -0.411      0.884 torch.float32\n",
      "  170             model.22.cv3.1.1.conv.weight     False        57600       [80, 80, 3, 3]  -0.000971    0.00925 torch.float32\n",
      "  171               model.22.cv3.1.1.bn.weight     False           80                 [80]       2.85       1.26 torch.float32\n",
      "  172                 model.22.cv3.1.1.bn.bias     False           80                 [80]       1.28       1.45 torch.float32\n",
      "  173                  model.22.cv3.1.2.weight     False         6400       [80, 80, 1, 1]    -0.0114     0.0527 torch.float32\n",
      "  174                    model.22.cv3.1.2.bias     False           80                 [80]      -10.5      0.911 torch.float32\n",
      "  175             model.22.cv3.2.0.conv.weight     False       184320      [80, 256, 3, 3]  -0.000242    0.00608 torch.float32\n",
      "  176               model.22.cv3.2.0.bn.weight     False           80                 [80]       1.12      0.328 torch.float32\n",
      "  177                 model.22.cv3.2.0.bn.bias     False           80                 [80]     -0.289      0.942 torch.float32\n",
      "  178             model.22.cv3.2.1.conv.weight     False        57600       [80, 80, 3, 3]   -0.00099    0.00803 torch.float32\n",
      "  179               model.22.cv3.2.1.bn.weight     False           80                 [80]       3.15       1.28 torch.float32\n",
      "  180                 model.22.cv3.2.1.bn.bias     False           80                 [80]       1.28       1.32 torch.float32\n",
      "  181                  model.22.cv3.2.2.weight     False         6400       [80, 80, 1, 1]    -0.0105     0.0502 torch.float32\n",
      "  182                    model.22.cv3.2.2.bias     False           80                 [80]      -9.61      0.937 torch.float32\n",
      "  183                 model.22.dfl.conv.weight     False           16        [1, 16, 1, 1]        7.5       4.76 torch.float32\n",
      "YOLOv8n summary: 225 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(225, 3157200, 0, 8.8575488)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "model.info(True, True)\n",
    "\n",
    "results = model.train(data=\"coco8.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolosam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
